{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import requests  \n",
    "\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import sys, urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搜索结果爬虫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(key, status=0, mode='isfuzzy', order=0, page=1, **kwargs):\n",
    "    '''\n",
    "        根据关键词搜索孔夫子旧书网所有商品，搜索结果返回前 5000 条\n",
    "        @param key: search keywords, str\n",
    "        @param status: product status, int, default 0; 0=在售, 1=已售\n",
    "        @param mode: search mode, str, default 'isfuzzy'; plain=普通, isfuzzy=模糊, exact=精确, perfect=完全匹配\n",
    "        @param order: sorting method, int, default 0; 0=综合, 1=价格升序, 2=价格降序, 3=出版时间降序, 4=出版时间升序, 6=最新上架, 7=书店等级, 100=运费升序\n",
    "        @param page: page num, int, default=1\n",
    "        @param kwargs: other conditions, Dict\n",
    "        @return result: search results, Dict\n",
    "    '''\n",
    "    encode_key = urllib.parse.quote(key)\n",
    "    \n",
    "    # 搜索条件\n",
    "    search_conditions = 'select=0&' + 'key=' + encode_key + '&status=' + str(status)\n",
    "    for key, value in kwargs.items():\n",
    "        value = value.encode('unicode_escape').decode()\n",
    "        pattern = re.compile(r'\\\\u')\n",
    "        encode_value  = re.sub(pattern, 'k', value)\n",
    "        search_conditions += '&' + key\n",
    "        if key=='author' or key=='press':\n",
    "            search_conditions += '=h' + str(encode_value)\n",
    "        else:\n",
    "            search_conditions += '=' + str(encode_value)\n",
    "    search_conditions += '&' + mode + '=1' + '&order=' + str(order) \n",
    "    if page != 1:\n",
    "        search_conditions += '&pagenum=' + str(page)\n",
    "    \n",
    "    #  Request URL \n",
    "    request_url = 'http://search.kongfz.com/product_result/?' + search_conditions + '&type=1' + '&ajaxdata=1' + '&_=' + str(round(time.time() * 1000))\n",
    "    \n",
    "    # Request Headers\n",
    "    my_headers = {\n",
    "        'Host': 'search.kongfz.com',\n",
    "        'Referer': 'http://search.kongfz.com/product_result/?' + search_conditions,\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.81 Safari/537.36',\n",
    "        'X-Requested-With': 'XMLHttpRequest',\n",
    "    }\n",
    "    \n",
    "    res = requests.post(url=request_url, headers = my_headers)  \n",
    "    res.raise_for_status()  \n",
    "    res.encoding = 'utf-8'  \n",
    "\n",
    "    # 得到包含搜索结果的字典\n",
    "    result = res.json()  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所需字段列表\n",
    "columns = ['itemid', 'itemname', 'shopid', 'shopname', 'area', 'areaname', \n",
    "           'author', 'press', 'price', 'binding', 'bindingname', 'pubdate', 'quality', 'qualityname', \n",
    "           'bigimgurl', 'smallimgurl', 'biztype', 'catid', 'class', 'importantdesc', 'isrelatedisbn', \n",
    "           'nickname', 'addtime', 'newaddtime', 'updatetime', 'years', 'years2', 'yearsgroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPageInfo(product_list):  \n",
    "    '''\n",
    "        对一个网页的商品信息进行解析，返回结果列表\n",
    "        @param product_list: product list, List\n",
    "        @return page_info_list: result list, List\n",
    "    '''  \n",
    "    page_info_list = []  \n",
    "    \n",
    "    for item in product_list:  \n",
    "        product_info = []  \n",
    "        for col in columns:\n",
    "            try:\n",
    "                product_info.append(item[col])\n",
    "            except:\n",
    "                product_info.append(None)\n",
    "        product_info.append('http://book.kongfz.com/' + item['itemid'] + '/' + item['shopid'])\n",
    "        page_info_list.append(product_info)  \n",
    "    \n",
    "    return page_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kongfzSearchSpider(key, status=0, mode='isfuzzy', order=0, page=1, **kwargs):  \n",
    "    '''\n",
    "        爬取孔夫子商品搜索结果列表数据\n",
    "        @param key: search keywords, str\n",
    "        @param status: product status, int, default 0; 0=在售, 1=已售\n",
    "        @param mode: search mode, str, default 'isfuzzy'; plain=普通, isfuzzy=模糊, exact=精确, perfect=完全匹配\n",
    "        @param order: sorting method, int, default 0; 0=综合, 1=价格升序, 2=价格降序, 3=出版时间降序, 4=出版时间升序, 6=最新上架, 7=书店等级, 100=运费升序\n",
    "        @param page: page num, int, default=1\n",
    "        @param kwargs: other conditions, Dict\n",
    "    '''\n",
    "    # 先爬取第一页，得到搜索结果的总记录数和总页数\n",
    "    result_dict = search(key, status, mode, order, page, **kwargs)\n",
    "    total_found = result_dict['other']['total_found'] #获取总记录数\n",
    "    page_num = result_dict['other']['page_count'] #获取总页数\n",
    "    print('商品总数：{0}，总页数：{1}'.format(total_found, page_num))  \n",
    "    time.sleep(30)\n",
    "    \n",
    "    # 对每个网页读取JSON, 获取每页数据 \n",
    "    total_info = [] \n",
    "    for n in range(1, page_num+1):  \n",
    "        result_dict = search(key, status, mode, order, page=n, **kwargs)  \n",
    "        item_list = result_dict['data']['itemList']\n",
    "        page_info = getPageInfo(item_list)\n",
    "        total_info += page_info  \n",
    "        time.sleep(random.randint(20, 40)) \n",
    "        print('已经抓取第 {0}/{1} 页'.format(n, page_num))\n",
    "       \n",
    "    #将所有数据转化为 DataFrame再输出 \n",
    "    columns.append('detail_url')\n",
    "    df = pd.DataFrame(data=total_info, columns=columns)   \n",
    "    data_output = 'output\\\\' + key + '_' + str(round(time.time())) + '.csv'\n",
    "    df.to_csv(data_output, index = False)  \n",
    "    print('已保存为 CSV 文件') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "商品总数：721，总页数：15\n",
      "已经抓取第 1/15 页\n",
      "已经抓取第 2/15 页\n",
      "已经抓取第 3/15 页\n",
      "已经抓取第 4/15 页\n",
      "已经抓取第 5/15 页\n",
      "已经抓取第 6/15 页\n",
      "已经抓取第 7/15 页\n",
      "已经抓取第 8/15 页\n",
      "已经抓取第 9/15 页\n",
      "已经抓取第 10/15 页\n",
      "已经抓取第 11/15 页\n",
      "已经抓取第 12/15 页\n",
      "已经抓取第 13/15 页\n",
      "已经抓取第 14/15 页\n",
      "已经抓取第 15/15 页\n",
      "已保存为 CSV 文件\n"
     ]
    }
   ],
   "source": [
    "kongfzSearchSpider('他改变了中国', mode='exact', order=6, press='上海译文出版社')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图书条目爬虫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
