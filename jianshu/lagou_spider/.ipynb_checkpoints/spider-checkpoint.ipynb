{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "import math  \n",
    "import pandas as pd  \n",
    "import time  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(url,num):  \n",
    "    '''\n",
    "        从网页获取JSON,使用POST请求,加上头部信息\n",
    "    '''\n",
    "    # Request Headers\n",
    "    my_headers = {  \n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36',  \n",
    "        'Host':'www.lagou.com',  \n",
    "        'Referer':'https://www.lagou.com/jobs/list_%E6%95%B0%E6%8D%AE%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86?city=%E5%B9%BF%E5%B7%9E&cl=false&fromSearch=true&labelWords=&suginput=',  \n",
    "        'X-Anit-Forge-Code':'0',  \n",
    "        'X-Anit-Forge-Token': 'None',  \n",
    "        'X-Requested-With':'XMLHttpRequest'  \n",
    "    }\n",
    "\n",
    "    # Form Data\n",
    "    my_data = {  \n",
    "        'first': 'true',  \n",
    "        'pn': num,  \n",
    "        'kd': '产品经理'\n",
    "    }  \n",
    "    \n",
    "    res = requests.post(url, headers = my_headers, data = my_data)  \n",
    "    res.raise_for_status()  \n",
    "    res.encoding = 'utf-8'  \n",
    "    \n",
    "    # 得到包含职位信息的字典  \n",
    "    page = res.json()  \n",
    "    return page  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_num(count):  \n",
    "    '''\n",
    "        计算要抓取的页数\n",
    "    '''  \n",
    "    # 每页15个职位,向上取整  \n",
    "    res = math.ceil(count/15)  \n",
    "    # 拉勾网最多显示30页结果  \n",
    "    if res > 30:  \n",
    "        return 30  \n",
    "    else:  \n",
    "        return res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_info(jobs_list):  \n",
    "    ''''\n",
    "        对一个网页的职位信息进行解析,返回列表\n",
    "    '''  \n",
    "    page_info_list = []  \n",
    "    \n",
    "    for i in jobs_list:  \n",
    "        job_info = []  \n",
    "        job_info.append(i['companyFullName'])  \n",
    "        job_info.append(i['companyShortName'])  \n",
    "        job_info.append(i['companySize'])  \n",
    "        job_info.append(i['financeStage'])  \n",
    "        job_info.append(i['district'])  \n",
    "        job_info.append(i['positionName'])  \n",
    "        job_info.append(i['workYear'])  \n",
    "        job_info.append(i['education'])  \n",
    "        job_info.append(i['salary'])  \n",
    "        job_info.append(i['positionAdvantage'])  \n",
    "        page_info_list.append(job_info)  \n",
    "    \n",
    "    return page_info_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():  \n",
    "    # Request URL\n",
    "    url = 'https://www.lagou.com/jobs/positionAjax.json?city=%E5%B9%BF%E5%B7%9E&needAddtionalResult=false'  \n",
    "    \n",
    "    # 先设定页数为1,获取总的职位数  \n",
    "    page_1 = get_json(url,1)  \n",
    "    total_count = page_1['content']['positionResult']['totalCount']  \n",
    "    num = get_page_num(total_count)  \n",
    "    total_info = []  \n",
    "    time.sleep(20)  \n",
    "    print('职位总数:{},页数:{}'.format(total_count,num))  \n",
    "\n",
    "    for n in range(1,num+1):  \n",
    "        # 对每个网页读取JSON, 获取每页数据  \n",
    "        page = get_json(url,n)  \n",
    "        jobs_list = page['content']['positionResult']['result']  \n",
    "        page_info = get_page_info(jobs_list)  \n",
    "        total_info += page_info  \n",
    "        print('已经抓取第{}页, 职位总数:{}'.format(n, len(total_info)))  \n",
    "        # 每次抓取完成后,暂停一会,防止被服务器拉黑  \n",
    "        time.sleep(30)  \n",
    "       \n",
    "    #将总数据转化为data frame再输出  \n",
    "    df = pd.DataFrame(data = total_info,columns = ['公司全名','公司简称','公司规模','融资阶段','区域','职位名称','工作经验','学历要求','工资','职位福利'])   \n",
    "    df.to_csv('spider_data.csv',index = False)  \n",
    "    \n",
    "    print('已保存为csv文件.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "职位总数:1157,页数:30\n",
      "已经抓取第1页, 职位总数:15\n",
      "已经抓取第2页, 职位总数:30\n",
      "已经抓取第3页, 职位总数:45\n",
      "已经抓取第4页, 职位总数:60\n",
      "已经抓取第5页, 职位总数:75\n",
      "已经抓取第6页, 职位总数:90\n",
      "已经抓取第7页, 职位总数:105\n",
      "已经抓取第8页, 职位总数:120\n",
      "已经抓取第9页, 职位总数:135\n",
      "已经抓取第10页, 职位总数:150\n",
      "已经抓取第11页, 职位总数:165\n",
      "已经抓取第12页, 职位总数:180\n",
      "已经抓取第13页, 职位总数:195\n",
      "已经抓取第14页, 职位总数:210\n",
      "已经抓取第15页, 职位总数:225\n",
      "已经抓取第16页, 职位总数:240\n",
      "已经抓取第17页, 职位总数:255\n",
      "已经抓取第18页, 职位总数:270\n",
      "已经抓取第19页, 职位总数:285\n",
      "已经抓取第20页, 职位总数:300\n",
      "已经抓取第21页, 职位总数:315\n",
      "已经抓取第22页, 职位总数:330\n",
      "已经抓取第23页, 职位总数:345\n",
      "已经抓取第24页, 职位总数:360\n",
      "已经抓取第25页, 职位总数:375\n",
      "已经抓取第26页, 职位总数:390\n",
      "已经抓取第27页, 职位总数:405\n",
      "已经抓取第28页, 职位总数:420\n",
      "已经抓取第29页, 职位总数:435\n",
      "已经抓取第30页, 职位总数:450\n",
      "已保存为csv文件.\n"
     ]
    }
   ],
   "source": [
    "if __name__== \"__main__\":   \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
